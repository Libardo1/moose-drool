<!DOCTYPE html>
<!-- saved from url=(0014)about:internet -->
<html>
<head>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8"/>

<title>Poisson log-linear regression - fitted by glm(), maximum likelihood, and MCMC</title>

<style type="text/css">
body, td {
   font-family: sans-serif;
   background-color: white;
   font-size: 12px;
   margin: 8px;
}

tt, code, pre {
   font-family: 'DejaVu Sans Mono', 'Droid Sans Mono', 'Lucida Console', Consolas, Monaco, monospace;
}

h1 { 
   font-size:2.2em; 
}

h2 { 
   font-size:1.8em; 
}

h3 { 
   font-size:1.4em; 
}

h4 { 
   font-size:1.0em; 
}

h5 { 
   font-size:0.9em; 
}

h6 { 
   font-size:0.8em; 
}

a:visited {
   color: rgb(50%, 0%, 50%);
}

pre {	
   margin-top: 0;
   max-width: 95%;
   border: 1px solid #ccc;
   white-space: pre-wrap;
}

pre code {
   display: block; padding: 0.5em;
}

code.r, code.cpp {
   background-color: #F8F8F8;
}

table, td, th {
  border: none;
}

blockquote {
   color:#666666;
   margin:0;
   padding-left: 1em;
   border-left: 0.5em #EEE solid;
}

hr {
   height: 0px;
   border-bottom: none;
   border-top-width: thin;
   border-top-style: dotted;
   border-top-color: #999999;
}

@media print {
   * { 
      background: transparent !important; 
      color: black !important; 
      filter:none !important; 
      -ms-filter: none !important; 
   }

   body { 
      font-size:12pt; 
      max-width:100%; 
   }
       
   a, a:visited { 
      text-decoration: underline; 
   }

   hr { 
      visibility: hidden;
      page-break-before: always;
   }

   pre, blockquote { 
      padding-right: 1em; 
      page-break-inside: avoid; 
   }

   tr, img { 
      page-break-inside: avoid; 
   }

   img { 
      max-width: 100% !important; 
   }

   @page :left { 
      margin: 15mm 20mm 15mm 10mm; 
   }
     
   @page :right { 
      margin: 15mm 10mm 15mm 20mm; 
   }

   p, h2, h3 { 
      orphans: 3; widows: 3; 
   }

   h2, h3 { 
      page-break-after: avoid; 
   }
}

</style>

<!-- Styles for R syntax highlighter -->
<style type="text/css">
   pre .operator,
   pre .paren {
     color: rgb(104, 118, 135)
   }

   pre .literal {
     color: rgb(88, 72, 246)
   }

   pre .number {
     color: rgb(0, 0, 205);
   }

   pre .comment {
     color: rgb(76, 136, 107);
   }

   pre .keyword {
     color: rgb(0, 0, 255);
   }

   pre .identifier {
     color: rgb(0, 0, 0);
   }

   pre .string {
     color: rgb(3, 106, 7);
   }
</style>

<!-- R syntax highlighter -->
<script type="text/javascript">
var hljs=new function(){function m(p){return p.replace(/&/gm,"&amp;").replace(/</gm,"&lt;")}function f(r,q,p){return RegExp(q,"m"+(r.cI?"i":"")+(p?"g":""))}function b(r){for(var p=0;p<r.childNodes.length;p++){var q=r.childNodes[p];if(q.nodeName=="CODE"){return q}if(!(q.nodeType==3&&q.nodeValue.match(/\s+/))){break}}}function h(t,s){var p="";for(var r=0;r<t.childNodes.length;r++){if(t.childNodes[r].nodeType==3){var q=t.childNodes[r].nodeValue;if(s){q=q.replace(/\n/g,"")}p+=q}else{if(t.childNodes[r].nodeName=="BR"){p+="\n"}else{p+=h(t.childNodes[r])}}}if(/MSIE [678]/.test(navigator.userAgent)){p=p.replace(/\r/g,"\n")}return p}function a(s){var r=s.className.split(/\s+/);r=r.concat(s.parentNode.className.split(/\s+/));for(var q=0;q<r.length;q++){var p=r[q].replace(/^language-/,"");if(e[p]){return p}}}function c(q){var p=[];(function(s,t){for(var r=0;r<s.childNodes.length;r++){if(s.childNodes[r].nodeType==3){t+=s.childNodes[r].nodeValue.length}else{if(s.childNodes[r].nodeName=="BR"){t+=1}else{if(s.childNodes[r].nodeType==1){p.push({event:"start",offset:t,node:s.childNodes[r]});t=arguments.callee(s.childNodes[r],t);p.push({event:"stop",offset:t,node:s.childNodes[r]})}}}}return t})(q,0);return p}function k(y,w,x){var q=0;var z="";var s=[];function u(){if(y.length&&w.length){if(y[0].offset!=w[0].offset){return(y[0].offset<w[0].offset)?y:w}else{return w[0].event=="start"?y:w}}else{return y.length?y:w}}function t(D){var A="<"+D.nodeName.toLowerCase();for(var B=0;B<D.attributes.length;B++){var C=D.attributes[B];A+=" "+C.nodeName.toLowerCase();if(C.value!==undefined&&C.value!==false&&C.value!==null){A+='="'+m(C.value)+'"'}}return A+">"}while(y.length||w.length){var v=u().splice(0,1)[0];z+=m(x.substr(q,v.offset-q));q=v.offset;if(v.event=="start"){z+=t(v.node);s.push(v.node)}else{if(v.event=="stop"){var p,r=s.length;do{r--;p=s[r];z+=("</"+p.nodeName.toLowerCase()+">")}while(p!=v.node);s.splice(r,1);while(r<s.length){z+=t(s[r]);r++}}}}return z+m(x.substr(q))}function j(){function q(x,y,v){if(x.compiled){return}var u;var s=[];if(x.k){x.lR=f(y,x.l||hljs.IR,true);for(var w in x.k){if(!x.k.hasOwnProperty(w)){continue}if(x.k[w] instanceof Object){u=x.k[w]}else{u=x.k;w="keyword"}for(var r in u){if(!u.hasOwnProperty(r)){continue}x.k[r]=[w,u[r]];s.push(r)}}}if(!v){if(x.bWK){x.b="\\b("+s.join("|")+")\\s"}x.bR=f(y,x.b?x.b:"\\B|\\b");if(!x.e&&!x.eW){x.e="\\B|\\b"}if(x.e){x.eR=f(y,x.e)}}if(x.i){x.iR=f(y,x.i)}if(x.r===undefined){x.r=1}if(!x.c){x.c=[]}x.compiled=true;for(var t=0;t<x.c.length;t++){if(x.c[t]=="self"){x.c[t]=x}q(x.c[t],y,false)}if(x.starts){q(x.starts,y,false)}}for(var p in e){if(!e.hasOwnProperty(p)){continue}q(e[p].dM,e[p],true)}}function d(B,C){if(!j.called){j();j.called=true}function q(r,M){for(var L=0;L<M.c.length;L++){if((M.c[L].bR.exec(r)||[null])[0]==r){return M.c[L]}}}function v(L,r){if(D[L].e&&D[L].eR.test(r)){return 1}if(D[L].eW){var M=v(L-1,r);return M?M+1:0}return 0}function w(r,L){return L.i&&L.iR.test(r)}function K(N,O){var M=[];for(var L=0;L<N.c.length;L++){M.push(N.c[L].b)}var r=D.length-1;do{if(D[r].e){M.push(D[r].e)}r--}while(D[r+1].eW);if(N.i){M.push(N.i)}return f(O,M.join("|"),true)}function p(M,L){var N=D[D.length-1];if(!N.t){N.t=K(N,E)}N.t.lastIndex=L;var r=N.t.exec(M);return r?[M.substr(L,r.index-L),r[0],false]:[M.substr(L),"",true]}function z(N,r){var L=E.cI?r[0].toLowerCase():r[0];var M=N.k[L];if(M&&M instanceof Array){return M}return false}function F(L,P){L=m(L);if(!P.k){return L}var r="";var O=0;P.lR.lastIndex=0;var M=P.lR.exec(L);while(M){r+=L.substr(O,M.index-O);var N=z(P,M);if(N){x+=N[1];r+='<span class="'+N[0]+'">'+M[0]+"</span>"}else{r+=M[0]}O=P.lR.lastIndex;M=P.lR.exec(L)}return r+L.substr(O,L.length-O)}function J(L,M){if(M.sL&&e[M.sL]){var r=d(M.sL,L);x+=r.keyword_count;return r.value}else{return F(L,M)}}function I(M,r){var L=M.cN?'<span class="'+M.cN+'">':"";if(M.rB){y+=L;M.buffer=""}else{if(M.eB){y+=m(r)+L;M.buffer=""}else{y+=L;M.buffer=r}}D.push(M);A+=M.r}function G(N,M,Q){var R=D[D.length-1];if(Q){y+=J(R.buffer+N,R);return false}var P=q(M,R);if(P){y+=J(R.buffer+N,R);I(P,M);return P.rB}var L=v(D.length-1,M);if(L){var O=R.cN?"</span>":"";if(R.rE){y+=J(R.buffer+N,R)+O}else{if(R.eE){y+=J(R.buffer+N,R)+O+m(M)}else{y+=J(R.buffer+N+M,R)+O}}while(L>1){O=D[D.length-2].cN?"</span>":"";y+=O;L--;D.length--}var r=D[D.length-1];D.length--;D[D.length-1].buffer="";if(r.starts){I(r.starts,"")}return R.rE}if(w(M,R)){throw"Illegal"}}var E=e[B];var D=[E.dM];var A=0;var x=0;var y="";try{var s,u=0;E.dM.buffer="";do{s=p(C,u);var t=G(s[0],s[1],s[2]);u+=s[0].length;if(!t){u+=s[1].length}}while(!s[2]);if(D.length>1){throw"Illegal"}return{r:A,keyword_count:x,value:y}}catch(H){if(H=="Illegal"){return{r:0,keyword_count:0,value:m(C)}}else{throw H}}}function g(t){var p={keyword_count:0,r:0,value:m(t)};var r=p;for(var q in e){if(!e.hasOwnProperty(q)){continue}var s=d(q,t);s.language=q;if(s.keyword_count+s.r>r.keyword_count+r.r){r=s}if(s.keyword_count+s.r>p.keyword_count+p.r){r=p;p=s}}if(r.language){p.second_best=r}return p}function i(r,q,p){if(q){r=r.replace(/^((<[^>]+>|\t)+)/gm,function(t,w,v,u){return w.replace(/\t/g,q)})}if(p){r=r.replace(/\n/g,"<br>")}return r}function n(t,w,r){var x=h(t,r);var v=a(t);var y,s;if(v){y=d(v,x)}else{return}var q=c(t);if(q.length){s=document.createElement("pre");s.innerHTML=y.value;y.value=k(q,c(s),x)}y.value=i(y.value,w,r);var u=t.className;if(!u.match("(\\s|^)(language-)?"+v+"(\\s|$)")){u=u?(u+" "+v):v}if(/MSIE [678]/.test(navigator.userAgent)&&t.tagName=="CODE"&&t.parentNode.tagName=="PRE"){s=t.parentNode;var p=document.createElement("div");p.innerHTML="<pre><code>"+y.value+"</code></pre>";t=p.firstChild.firstChild;p.firstChild.cN=s.cN;s.parentNode.replaceChild(p.firstChild,s)}else{t.innerHTML=y.value}t.className=u;t.result={language:v,kw:y.keyword_count,re:y.r};if(y.second_best){t.second_best={language:y.second_best.language,kw:y.second_best.keyword_count,re:y.second_best.r}}}function o(){if(o.called){return}o.called=true;var r=document.getElementsByTagName("pre");for(var p=0;p<r.length;p++){var q=b(r[p]);if(q){n(q,hljs.tabReplace)}}}function l(){if(window.addEventListener){window.addEventListener("DOMContentLoaded",o,false);window.addEventListener("load",o,false)}else{if(window.attachEvent){window.attachEvent("onload",o)}else{window.onload=o}}}var e={};this.LANGUAGES=e;this.highlight=d;this.highlightAuto=g;this.fixMarkup=i;this.highlightBlock=n;this.initHighlighting=o;this.initHighlightingOnLoad=l;this.IR="[a-zA-Z][a-zA-Z0-9_]*";this.UIR="[a-zA-Z_][a-zA-Z0-9_]*";this.NR="\\b\\d+(\\.\\d+)?";this.CNR="\\b(0[xX][a-fA-F0-9]+|(\\d+(\\.\\d*)?|\\.\\d+)([eE][-+]?\\d+)?)";this.BNR="\\b(0b[01]+)";this.RSR="!|!=|!==|%|%=|&|&&|&=|\\*|\\*=|\\+|\\+=|,|\\.|-|-=|/|/=|:|;|<|<<|<<=|<=|=|==|===|>|>=|>>|>>=|>>>|>>>=|\\?|\\[|\\{|\\(|\\^|\\^=|\\||\\|=|\\|\\||~";this.ER="(?![\\s\\S])";this.BE={b:"\\\\.",r:0};this.ASM={cN:"string",b:"'",e:"'",i:"\\n",c:[this.BE],r:0};this.QSM={cN:"string",b:'"',e:'"',i:"\\n",c:[this.BE],r:0};this.CLCM={cN:"comment",b:"//",e:"$"};this.CBLCLM={cN:"comment",b:"/\\*",e:"\\*/"};this.HCM={cN:"comment",b:"#",e:"$"};this.NM={cN:"number",b:this.NR,r:0};this.CNM={cN:"number",b:this.CNR,r:0};this.BNM={cN:"number",b:this.BNR,r:0};this.inherit=function(r,s){var p={};for(var q in r){p[q]=r[q]}if(s){for(var q in s){p[q]=s[q]}}return p}}();hljs.LANGUAGES.cpp=function(){var a={keyword:{"false":1,"int":1,"float":1,"while":1,"private":1,"char":1,"catch":1,"export":1,virtual:1,operator:2,sizeof:2,dynamic_cast:2,typedef:2,const_cast:2,"const":1,struct:1,"for":1,static_cast:2,union:1,namespace:1,unsigned:1,"long":1,"throw":1,"volatile":2,"static":1,"protected":1,bool:1,template:1,mutable:1,"if":1,"public":1,friend:2,"do":1,"return":1,"goto":1,auto:1,"void":2,"enum":1,"else":1,"break":1,"new":1,extern:1,using:1,"true":1,"class":1,asm:1,"case":1,typeid:1,"short":1,reinterpret_cast:2,"default":1,"double":1,register:1,explicit:1,signed:1,typename:1,"try":1,"this":1,"switch":1,"continue":1,wchar_t:1,inline:1,"delete":1,alignof:1,char16_t:1,char32_t:1,constexpr:1,decltype:1,noexcept:1,nullptr:1,static_assert:1,thread_local:1,restrict:1,_Bool:1,complex:1},built_in:{std:1,string:1,cin:1,cout:1,cerr:1,clog:1,stringstream:1,istringstream:1,ostringstream:1,auto_ptr:1,deque:1,list:1,queue:1,stack:1,vector:1,map:1,set:1,bitset:1,multiset:1,multimap:1,unordered_set:1,unordered_map:1,unordered_multiset:1,unordered_multimap:1,array:1,shared_ptr:1}};return{dM:{k:a,i:"</",c:[hljs.CLCM,hljs.CBLCLM,hljs.QSM,{cN:"string",b:"'\\\\?.",e:"'",i:"."},{cN:"number",b:"\\b(\\d+(\\.\\d*)?|\\.\\d+)(u|U|l|L|ul|UL|f|F)"},hljs.CNM,{cN:"preprocessor",b:"#",e:"$"},{cN:"stl_container",b:"\\b(deque|list|queue|stack|vector|map|set|bitset|multiset|multimap|unordered_map|unordered_set|unordered_multiset|unordered_multimap|array)\\s*<",e:">",k:a,r:10,c:["self"]}]}}}();hljs.LANGUAGES.r={dM:{c:[hljs.HCM,{cN:"number",b:"\\b0[xX][0-9a-fA-F]+[Li]?\\b",e:hljs.IMMEDIATE_RE,r:0},{cN:"number",b:"\\b\\d+(?:[eE][+\\-]?\\d*)?L\\b",e:hljs.IMMEDIATE_RE,r:0},{cN:"number",b:"\\b\\d+\\.(?!\\d)(?:i\\b)?",e:hljs.IMMEDIATE_RE,r:1},{cN:"number",b:"\\b\\d+(?:\\.\\d*)?(?:[eE][+\\-]?\\d*)?i?\\b",e:hljs.IMMEDIATE_RE,r:0},{cN:"number",b:"\\.\\d+(?:[eE][+\\-]?\\d*)?i?\\b",e:hljs.IMMEDIATE_RE,r:1},{cN:"keyword",b:"(?:tryCatch|library|setGeneric|setGroupGeneric)\\b",e:hljs.IMMEDIATE_RE,r:10},{cN:"keyword",b:"\\.\\.\\.",e:hljs.IMMEDIATE_RE,r:10},{cN:"keyword",b:"\\.\\.\\d+(?![\\w.])",e:hljs.IMMEDIATE_RE,r:10},{cN:"keyword",b:"\\b(?:function)",e:hljs.IMMEDIATE_RE,r:2},{cN:"keyword",b:"(?:if|in|break|next|repeat|else|for|return|switch|while|try|stop|warning|require|attach|detach|source|setMethod|setClass)\\b",e:hljs.IMMEDIATE_RE,r:1},{cN:"literal",b:"(?:NA|NA_integer_|NA_real_|NA_character_|NA_complex_)\\b",e:hljs.IMMEDIATE_RE,r:10},{cN:"literal",b:"(?:NULL|TRUE|FALSE|T|F|Inf|NaN)\\b",e:hljs.IMMEDIATE_RE,r:1},{cN:"identifier",b:"[a-zA-Z.][a-zA-Z0-9._]*\\b",e:hljs.IMMEDIATE_RE,r:0},{cN:"operator",b:"<\\-(?!\\s*\\d)",e:hljs.IMMEDIATE_RE,r:2},{cN:"operator",b:"\\->|<\\-",e:hljs.IMMEDIATE_RE,r:1},{cN:"operator",b:"%%|~",e:hljs.IMMEDIATE_RE},{cN:"operator",b:">=|<=|==|!=|\\|\\||&&|=|\\+|\\-|\\*|/|\\^|>|<|!|&|\\||\\$|:",e:hljs.IMMEDIATE_RE,r:0},{cN:"operator",b:"%",e:"%",i:"\\n",r:1},{cN:"identifier",b:"`",e:"`",r:0},{cN:"string",b:'"',e:'"',c:[hljs.BE],r:0},{cN:"string",b:"'",e:"'",c:[hljs.BE],r:0},{cN:"paren",b:"[[({\\])}]",e:hljs.IMMEDIATE_RE,r:0}]}};
hljs.initHighlightingOnLoad();
</script>


<!-- MathJax scripts -->
<script type="text/javascript" src="https://c328740.ssl.cf1.rackcdn.com/mathjax/2.0-latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML">
</script>



</head>

<body>
<h1>Poisson log-linear regression - fitted by glm(), maximum likelihood, and MCMC</h1>

<p>The goal of this post is to demonstrate how a simple statistical model (Poisson log-linear regression) can be fitted using three different approaches. I want to demonstrate that both frequentists and Bayesians use the same models, and that it is the fitting procedure and the inference that differs. This is also for those who understand the likelihood methods and do not have a clue about MCMC, and vice versa. I use an ecological dataset for the demonstration.</p>

<p>The complete code of this post is available <a href="https://github.com/petrkeil/Statistics/tree/master/Poisson_regression">here on GitHub</a></p>

<hr/>

<h1>The data</h1>

<p>I will use the data on the distribution of 3605 individual trees of <em>Beilschmiedia pendula</em> in 50-ha (500 x 1000 m) forest plot in Barro Colorado (Panama). The dataset is freely available as a part of the R&#39;s <code>spatstat</code> library. </p>

<p>First, I will load the necessary libraries:</p>

<pre><code class="r">library(spatstat)
</code></pre>

<pre><code>## Error: there is no package called &#39;spatstat&#39;
</code></pre>

<pre><code class="r">library(raster)
</code></pre>

<pre><code>## Error: there is no package called &#39;raster&#39;
</code></pre>

<pre><code class="r">library(sp)
</code></pre>

<pre><code>## Error: there is no package called &#39;sp&#39;
</code></pre>

<p>Let&#39;s plot the spatial distribution of the individuals in the plot:</p>

<pre><code class="r">plot(bei$x, bei$y, pch = 19, cex = 0.5, main = &quot;Spatial distribution of individuals in the 50-ha Barro Colorado plot&quot;, 
    xlab = &quot;x coordinate [m]&quot;, ylab = &quot;y coordinate [m]&quot;, frame = FALSE)
</code></pre>

<pre><code>## Error: object &#39;bei&#39; not found
</code></pre>

<pre><code class="r">abline(h = 0, col = &quot;grey&quot;)
</code></pre>

<pre><code>## Error: plot.new has not been called yet
</code></pre>

<pre><code class="r">abline(h = 500, col = &quot;grey&quot;)
</code></pre>

<pre><code>## Error: plot.new has not been called yet
</code></pre>

<pre><code class="r">abline(v = 0, col = &quot;grey&quot;)
</code></pre>

<pre><code>## Error: plot.new has not been called yet
</code></pre>

<pre><code class="r">abline(v = 1000, col = &quot;grey&quot;)
</code></pre>

<pre><code>## Error: plot.new has not been called yet
</code></pre>

<p>The dataset also comes with two rasterized environmental layers: elevation and slope.  My goal will be to model density of tree individuals as a function of elevation [meters above sea level]. I am interested in predicting density of the trees (i.e. number <strong>n</strong> of individuals per unit area). Hence, I will resample the data into a grid of 50 x 50 m:</p>

<pre><code class="r"># coarsening the predictor data into the 50 x 50 m grid by taking the mean
# of the 5 x 5 m grid cells:
elev &lt;- raster(bei.extra[[1]])
</code></pre>

<pre><code>## Error: could not find function &quot;raster&quot;
</code></pre>

<pre><code class="r"># cropping the data so that they have exactly 500 x 1000 cells
ext &lt;- extent(2.5, 1002.5, 2.5, 1002.5)
</code></pre>

<pre><code>## Error: could not find function &quot;extent&quot;
</code></pre>

<pre><code class="r">elev &lt;- crop(elev, ext)
</code></pre>

<pre><code>## Error: could not find function &quot;crop&quot;
</code></pre>

<pre><code class="r"># aggregating the elevation data
elev50 &lt;- aggregate(elev, fact = 10, fun = mean)
</code></pre>

<pre><code>## Error: object &#39;elev&#39; not found
</code></pre>

<pre><code class="r">
# fitting the point data into the 40 x 40 m grid
xy &lt;- data.frame(x = bei$x, y = bei$y)
</code></pre>

<pre><code>## Error: object &#39;bei&#39; not found
</code></pre>

<pre><code class="r">n50 &lt;- rasterize(xy, elev50, fun = &quot;count&quot;)
</code></pre>

<pre><code>## Error: could not find function &quot;rasterize&quot;
</code></pre>

<pre><code class="r"># replacing the NA values by 0
n50[is.na(n50)] &lt;- 0
</code></pre>

<pre><code>## Error: object &#39;n50&#39; not found
</code></pre>

<h3>Initial data visualization</h3>

<p>Initial plotting of the data is the necessary first step in any data analysis. So let&#39;s first plot the gridded data:</p>

<pre><code class="r">plot(stack(elev50, n50), main = c(&quot;Predictor: Mean Elevation in 50x50 m cells&quot;, 
    &quot;Response: # of Individuals in 50x50 m cells&quot;), axes = FALSE)
</code></pre>

<pre><code>## Error: object &#39;elev50&#39; not found
</code></pre>

<p>Now let&#39;s see how the predictor and the response look plotted against each other. </p>

<pre><code class="r">plot(elev50[], n50[], cex = 1, pch = 19, col = &quot;grey&quot;, ylab = &quot;# of Individuals&quot;, 
    xlab = &quot;Mean Elevation [m]&quot;)
</code></pre>

<pre><code>## Error: object &#39;elev50&#39; not found
</code></pre>

<p>There seems to be a unimodal response of # of individuals to elevation. For this reason I will use a polynomial function rather than the simplest (linear) function to model the response. Also, you can see that the variability of the data increases in intermediate elevations, and I also note that this is count data &ndash; it makes it an excellent candidate for Poisson error structure (the larger the mean the larger the variance), or maybe even Negative-binomial error structure (not considered in this post). </p>

<h3>Centering and standardization</h3>

<p>I find it necessary to center (to 0 mean) and standardize (to variance of 1) variables for MCMC simulations and for likelihood optimization. For models with log link function it really is essential &ndash;  it makes any algorithm opearting in log-space much more effective. Here I will define my own function <code>scale2()</code>, but you can also use the R&#39;s native <code>scale()</code>: </p>

<pre><code class="r">scale2 &lt;- function(x) {
    sdx &lt;- sqrt(var(x))
    meanx &lt;- mean(x)
    return((x - meanx)/sdx)
}

elev50 &lt;- scale2(elev50[])
</code></pre>

<pre><code>## Error: object &#39;elev50&#39; not found
</code></pre>

<p>Finally, some minor tweakings:</p>

<pre><code class="r">pow.elev50 &lt;- elev50^2  # (I will be fitting a polynomial)
</code></pre>

<pre><code>## Error: object &#39;elev50&#39; not found
</code></pre>

<pre><code class="r">n50 &lt;- n50[]
</code></pre>

<pre><code>## Error: object &#39;n50&#39; not found
</code></pre>

<hr/>

<h1>The model</h1>

<p>This is the formal definition of the model that I am going to use: </p>

<p>\( \log \lambda_i = \beta_0 + \beta_1 Elevation_i + \beta_2 Elevation_i^2 \)</p>

<p>\( n_i \sim Poisson(\lambda_i) \)</p>

<p>The index \( i \) identifies each grid cell (data point). \( \beta_0 \) - \( \beta_2 \) are model coefficients, and \( n_i \) is the observed number of individuals in each grid cell.</p>

<p>The notation roughly reads as: The logarithm of \( \lambda_i \) is a function of the elevation and the regression coefficients. The observed numbers of individuals in each grid cell is an outcome of a Poisson-distributed random process with cell-specific parameter \( \lambda_i \).</p>

<p>I recommend to write down such formal definition of any statistical model that you are going to use. It will tell you everything about its assumptions and it will be easier to interpret the fitted model.</p>

<hr/>

<h1>Fitting the model using glm()</h1>

<p>Fitting my model with the <code>glm()</code> function is easy. You just need to specify that the data are drawn from Poisson distribution and that \( \lambda_i \) is modelled in logarithmic space. Specifying <code>family=&quot;poisson&quot;</code> will do exactly that:</p>

<pre><code class="r">m.glm &lt;- glm(n50 ~ elev50 + pow.elev50, family = &quot;poisson&quot;)
</code></pre>

<pre><code>## Error: object &#39;n50&#39; not found
</code></pre>

<pre><code class="r">summary(m.glm)
</code></pre>

<pre><code>## Error: object &#39;m.glm&#39; not found
</code></pre>

<p>I will then use the fitted model to make a smooth prediction curve of \( \lambda_i \):</p>

<pre><code class="r">elev.seq &lt;- seq(-3, 2, by = 0.05)
new.data &lt;- data.frame(elev50 = elev.seq, pow.elev50 = elev.seq^2)
new.predict &lt;- predict(m.glm, newdata = new.data, type = &quot;response&quot;)
</code></pre>

<pre><code>## Error: object &#39;m.glm&#39; not found
</code></pre>

<p>And here I plot the data and the predicted \( \lambda_i \) (red line):</p>

<pre><code class="r">plot(elev50, n50, cex = 1, col = &quot;lightgrey&quot;, pch = 19, ylab = &quot;# of Individuals&quot;, 
    xlab = &quot;Scaled Mean Elevation&quot;)
</code></pre>

<pre><code>## Error: object &#39;elev50&#39; not found
</code></pre>

<pre><code class="r">lines(elev.seq, new.predict, col = &quot;red&quot;, lwd = 2)
</code></pre>

<pre><code>## Error: object &#39;new.predict&#39; not found
</code></pre>

<h3>Advantages of glm()</h3>

<ul>
<li>Fast.</li>
<li>Simple.</li>
<li>It immediately gives you AIC, SEs, R<sup>2</sup> and the other cool stuff.</li>
<li>It works well even on relatively big data.</li>
</ul>

<h3>Disadvantages of glm()</h3>

<ul>
<li>Not very flexible.</li>
<li>It is tricky to pull out prediction intervals. In my case I could use some combination of bootstrap and <code>qpois()</code>, but it would get quite messy in any case.</li>
</ul>

<hr/>

<h1>Fitting the model by maximum likelihood</h1>

<p>First, I will define the log-likelihood function for the polynomial Poisson regression: </p>

<pre><code class="r">LogLike &lt;- function(dat, par) {
    beta0 &lt;- par[1]
    beta1 &lt;- par[2]
    beta2 &lt;- par[3]
    # the deterministic part of the model:
    lambda &lt;- exp(beta0 + beta1 * dat$x + beta2 * (dat$x^2))
    # and here comes the negative log-likelihood of the whole dataset, given the
    # model:
    LL &lt;- -sum(dpois(dat$y, lambda, log = TRUE))
    return(LL)
}
</code></pre>

<p>Then I need to set the initial values for the optimization procedure:</p>

<pre><code class="r">beta0 &lt;- rnorm(1)
beta1 &lt;- rnorm(1)
beta2 &lt;- rnorm(1)
par &lt;- c(beta0, beta1, beta2)
</code></pre>

<p>I will coerce my data for my <code>LogLike()</code> function:</p>

<pre><code class="r">dat &lt;- data.frame(y = n50, x = elev50)
</code></pre>

<pre><code>## Error: object &#39;n50&#39; not found
</code></pre>

<p>And now I can run the likelihood maximization using the <code>optim()</code> function.</p>

<pre><code class="r">m.like &lt;- optim(par = par, fn = LogLike, dat = dat)
</code></pre>

<pre><code>## Error: object &#39;dat&#39; not found
</code></pre>

<pre><code class="r">m.like
</code></pre>

<pre><code>## Error: object &#39;m.like&#39; not found
</code></pre>

<p>Note: I am using the scaled (to zero mean and unit variance) predictor <code>elev50</code>. This is vital in case you are using a GLM with log link function. If you try to run the <code>optim()</code> function on raw (non-scaled) data, it won&#39;t work. </p>

<p>And finally, plotting the data and the fitted model:</p>

<pre><code class="r">plot(elev50, n50, cex = 1, col = &quot;lightgrey&quot;, pch = 19, ylab = &quot;# of Individuals&quot;, 
    xlab = &quot;Scaled Mean Elevation&quot;)
</code></pre>

<pre><code>## Error: object &#39;elev50&#39; not found
</code></pre>

<pre><code class="r">new.predict &lt;- exp(m.like$par[1] + m.like$par[2] * elev.seq + m.like$par[3] * 
    (elev.seq^2))
</code></pre>

<pre><code>## Error: object &#39;m.like&#39; not found
</code></pre>

<pre><code class="r">lines(elev.seq, new.predict, col = &quot;red&quot;, lwd = 2)
</code></pre>

<pre><code>## Error: object &#39;new.predict&#39; not found
</code></pre>

<h3>Advantages of likelihood optimization</h3>

<ul>
<li>More flexible than <code>glm()</code> - you can modify your models as much as you want and you will be able to fit them.</li>
<li>Often faster than MCMC.</li>
</ul>

<h3>Disadvantages of likelihood optimization</h3>

<ul>
<li>The optimization algorithm may crash, or it can get stuck at a local optimum.</li>
<li>Difficult to get prediction intervals (or any measure of uncertainty).</li>
</ul>

<hr/>

<h1>Fitting the model by MCMC in JAGS</h1>

<p>MCMC stands for Markov Chain Monte Carlo sampling. It can be used to estimate posterior distributions of model parameters (i.e. to &ldquo;fit a model&rdquo;) in a Bayesian setting. The most common flavors of MCMC are Metropolis-Hastings algorithm and Gibbs sampling.
I will use the MCMC sampler in <a href="http://mcmc-jags.sourceforge.net/">JAGS</a> to fit the model, which in R is accessed conveniently through the <code>rjags</code> library:</p>

<pre><code class="r">library(rjags)
</code></pre>

<pre><code>## Error: there is no package called &#39;rjags&#39;
</code></pre>

<p>Now I will create the <code>list</code> data for JAGS:</p>

<pre><code class="r">jags.data &lt;- list(N.cells = length(n50), n50 = n50, elev50 = elev50)
</code></pre>

<pre><code>## Error: object &#39;n50&#39; not found
</code></pre>

<p>And this is the model written in the JAGS (BUGS) language, which is very similar to R, but it is not the same:</p>

<pre><code>  cat(&quot;
      model
      {
        # priors
        beta0 ~ dnorm(0,0.001)
        beta1 ~ dnorm(0,0.001)
        beta2 ~ dnorm(0,0.001)

        # likelihood
        for(i in 1:N.cells)
        {
          n50[i] ~ dpois(lambda[i])
          log(lambda[i]) &lt;- beta0 + beta1*elev50[i] + beta2*pow(elev50[i],2)
          # this part is here in order to make nice prediction curves:
          prediction[i] ~ dpois(lambda[i])
        } 
      }
  &quot;, file=&quot;model.txt&quot;)
</code></pre>

<p>I have actually dumped the code into a file.</p>

<p>Here I specify the parameters that will be monitored during the MCMC sampling:</p>

<pre><code class="r">params &lt;- c(&quot;beta0&quot;, &quot;beta1&quot;, &quot;beta2&quot;, &quot;prediction&quot;)
</code></pre>

<p>Compiling the model:</p>

<pre><code class="r">jm &lt;- jags.model(&quot;model.txt&quot;, data = jags.data, n.chains = 3, n.adapt = 1000)
</code></pre>

<pre><code>## Error: could not find function &quot;jags.model&quot;
</code></pre>

<p>You usually need to throw away the initial samples (the so-called &ldquo;burn-in&rdquo; phase):</p>

<pre><code class="r">update(jm, n.iter = 1000)
</code></pre>

<pre><code>## Error: object &#39;jm&#39; not found
</code></pre>

<p>And here I am sampling from the posteriors and I am saving the samples for inference:</p>

<pre><code class="r">jm.sample &lt;- jags.samples(jm, variable.names = params, n.iter = 1000, thin = 1)
</code></pre>

<pre><code>## Error: could not find function &quot;jags.samples&quot;
</code></pre>

<p>I can plot the Markov chains of the three regression coefficients, and their posterior density plots which are marginal distributions of the chains:</p>

<pre><code class="r">plot(as.mcmc.list(jm.sample$beta0), main = &quot;Beta_0&quot;)
</code></pre>

<pre><code>## Error: could not find function &quot;as.mcmc.list&quot;
</code></pre>

<pre><code class="r">plot(as.mcmc.list(jm.sample$beta1), main = &quot;Beta_1&quot;)
</code></pre>

<pre><code>## Error: could not find function &quot;as.mcmc.list&quot;
</code></pre>

<pre><code class="r">plot(as.mcmc.list(jm.sample$beta2), main = &quot;Beta_2&quot;)
</code></pre>

<pre><code>## Error: could not find function &quot;as.mcmc.list&quot;
</code></pre>

<p>Here I pull out a summary for an individual parameter, e.g. \( \beta_2 \):</p>

<pre><code class="r">summary(as.mcmc.list(jm.sample$beta2))
</code></pre>

<pre><code>## Error: could not find function &quot;as.mcmc.list&quot;
</code></pre>

<p>I pull out the predictions and the 95% Prediction Intervals:</p>

<pre><code class="r">predictions &lt;- summary(as.mcmc.list(jm.sample$prediction))
</code></pre>

<pre><code>## Error: could not find function &quot;as.mcmc.list&quot;
</code></pre>

<pre><code class="r">prds &lt;- data.frame(sc50 = scale2(elev50), predictions$quantiles)
</code></pre>

<pre><code>## Error: object &#39;elev50&#39; not found
</code></pre>

<pre><code class="r">prds &lt;- prds[order(prds[, 1]), ]
</code></pre>

<pre><code>## Error: object &#39;prds&#39; not found
</code></pre>

<p>And here I plot it all:</p>

<pre><code class="r">plot(scale2(elev50), n50, cex = 1, col = &quot;lightgrey&quot;, pch = 19, ylab = &quot;# of Individuals&quot;, 
    xlab = &quot;Scaled Mean Elevation&quot;)
</code></pre>

<pre><code>## Error: object &#39;elev50&#39; not found
</code></pre>

<pre><code class="r">lines(prds[, 1], prds[, 2], lwd = 2)
</code></pre>

<pre><code>## Error: object &#39;prds&#39; not found
</code></pre>

<pre><code class="r">lines(prds[, 1], prds[, 4], lwd = 2, col = &quot;red&quot;)
</code></pre>

<pre><code>## Error: object &#39;prds&#39; not found
</code></pre>

<pre><code class="r">lines(prds[, 1], prds[, 6], lwd = 2)
</code></pre>

<pre><code>## Error: object &#39;prds&#39; not found
</code></pre>

<pre><code class="r">
legend(&quot;topleft&quot;, legend = c(&quot;95% P.I.&quot;, &quot;lambda_i&quot;), col = c(&quot;black&quot;, &quot;red&quot;), 
    lwd = c(2, 2))
</code></pre>

<pre><code>## Error: plot.new has not been called yet
</code></pre>

<p>You can see that the estimated parameter values very well match those from <code>glm()</code> and from the ML optimization. The striking result is that the data are clearly over-dispersed. Prediction intervals are really good at showing that &ndash; the data simply spread a lot out of the black P.I. boundaries. </p>

<h3>Advantages of MCMC</h3>

<ul>
<li>Flexible - you can modify your models as much as you want and still effectively fit them.</li>
<li>Reliable. It will never get stuck on a local optimum.</li>
<li>Great in pulling out uncertainties of all kinds (e.g. in the form of Prediction Intervals).</li>
<li>Even though the MCMC procedure is complicated, the inference based on the posterior distributions is very easy and intuitive.</li>
</ul>

<h3>Disadvantages of MCMC</h3>

<ul>
<li>Often slow. For more complex models or large datasets it can be a pain.</li>
<li>It may be tedious to code and debug.</li>
</ul>

<hr/>

<h1>Summary</h1>

<p>The three approaches gave roughly the same mean predicted values and the same mean estimates of model parameters. In contrast to glm() and ML otpimization, MCMC enabled me to monitor the full posterior distribution of predictions that included both uncertainty in the model estimation (given mostly by sample size) as well as uncertainty given by the variance of the Poisson distribution.</p>

<p>The model obviously is not ideal: the data are clearly over-dispersed. Negative Binomial or quazi-Poisson models would probably be more appropriate.</p>

<p>An additional next thing to explore would be spatial dependence (spatial autocorrelation). </p>

</body>

</html>

